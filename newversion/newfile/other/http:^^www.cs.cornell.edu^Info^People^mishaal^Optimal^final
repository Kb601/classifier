optimal video transmission

optimal video transmission
by mishaal almashan
advised by dexter kozen
meng project,  fall 1995
computer science department
cornell university

table of contents

project title
introduction
quick overview of mpeg
	history
	compression algorithm
	mpeg frames
	motion vectors
problem
aim of this project
research sources/notes
links to relavent topics
demo output of current mpeg_weigh on redsnightmare.mpg
mpeg_weigh reads in an mpeg-1 video file and parses the frames to extract the motion vectors of blocks within the frames. it determines how much of a sweeping pan occured, by averaging out all the motion vectors into a single vector, and caculating how far is the referenced frame. the panindex then would be proportional to the motion vector and inversely proportional to the distance to the referenced frame (in frames). 

 cmt extension



introduction
	this project will improve upon an existing prioritization algorithm
for bandwidth-constrained video transmission.  the object is to
determine which frames of a video sequence to drop so as to optimize
perceptual continuity of the received sequence.  the algorithm will be
modified to take the rate of motion into account when prioritizing
frames for transmission, so that frames with more motion are less likely
to be dropped.  
	an algorithm was developed that would drop the least critical
frames in a video stream when the transmission bandwidth is narrow.   
the algorithm, described in  efficient algorithms for optimal video transmission,   was proved
to be optimal for most video,  but when it comes to video with a lot of
scenery motion (as in panning and scanning) it fails.  so the aim of
this project is to account for the rate of motion and assign weights to
the frames so as to drop the least weighted frames and still preserve
perceptual continuity. it will explore and study the motion vectors in
mpeg encoded video and try to determine from that how critical is the
frame. 


quick overview of mpeg-1
history

the moving pricture expert group (mpeg) comitee, a group under the international
standards organization (iso),  started it's effort to draft a standard for digital
video and audio compression in 1988. eventhough a standard for video compression
to be used in teleconferencing and telephony applications had existed (ccit recommendation 
h.261),  mpeg realized that by relaxing the constraints on very low delay and focus
on low bit rate it can achieve good quality video in the range of 1-1.5 mbits/s.   

compression algorithms

so by september of 1990, a draft proposal was agreed upon by the members of the group.
this draft describes a video compression that uses block-based motion compensation
for temporal redundancy and transform domain (discrete cosine transform) based 
compression for spatial redundancy. motion compensation occurs by predicting motion 
between 16x16 macroblocks of frames in the temporal direction (motion-vectors), then the prediction 
error in 8x8 macroblocks of the frames can be compresssed using the redundancy in the spatial direction 
with dct.  the resulting dct coefficients are quantized to drop the unnecessary precision.
this qautization often results in the coeffecients to be zero.  these coefficients, along
with the motion vectors, dc components, quantization values, and other parameters are then
huffman coded using fixed tables.  the dct coefficients have a special two dimentional huffman
table that would code the non-zero value and the run-length of zeros.  the motion vectors and dc
components are also subtracted from the last one coded (dpcm).

mpeg frames
the standards called for random access, fast forward and reverse searches, reverse playback, and 
audio-visual synchronization.  this required reference frames, which are called intraframes (i).
these frames are sill images having no dependency on any other frames.  on the other hand, predicted 
frames (p) depend on past i or p frames to be reconstruct during decoding.  each macroblock of these
p frames can come with either a vector and difference dct coefficients of the last i or p frame,  or it
can be intra coded (just like i frames).
the last type of frames is the bidirectional frame (b),  which can depend on past and future i or p
frames.  the macroblocks of b frames can be any of the following four types:

intracoded, no dependency. 
backward dependency, in which a block is referenceing a block in the past
forward dependency, in which a block is referencing a block in the future
average, in which a block is the difference of the average of both a past and future block


figure o.1: mpeg frames
these dependencies are better illustrated in figure o.1
one can see how p frames depend on past i or p frames while b frames can depend on both i or p in the
future or past.  these dependencies mean that when decoding mpeg, b frames cannot be decoded until the
depended opon i or p frames are decoded.  this might require the decoder to decode a future frame, in order
to decode a current b frame.
motion vectors
(motion detection/motion estimation)

problem with the current algorithm
as described before,  the current algorithm treats the frames equally.  the weighing 
procedure used involves weighing frames according to the the frame type and the frame's
 dependecies.  so, for example,  when a frame is used as a reference for multiple frames, it 
would be weighted heavier than a frame with one frame dependence. 
such an algorithm is optimal in the sense of data throughput,  but the aim is to have
a transmission that is perceptually acceptable.  currently, there is no way of knowing
what information a frame contains;  therefore, the maximum number of frames are sent not the most 
perceptually-critical frames. this fault causes the video at reception to look jittery.  this is 
especially true when there is panning in the scence.

aim of this project
knowing that mpeg video frames carry motion vectors, and that frames with more motion are 
perceptualy-ciritcal, we can use these vectors as motion detectors. this allows us to 
distinguish these frames, and hence weigh them accordingly.
the aim of this project is to extract the motion vectors and somehow use them to weigh the
different frames.  the old algorithm would then take into account these new weights to produce a squence of frames that are more perceptually acceptable.
 

research sources/notes

 dexter kozen, yaron minsky, and brian smith. efficient algorithms for optimal video transmission.technical report tr95-1517, cornell university, may 1995.

le gall, didier mpeg: a video compression standard for
multimedia applications, communications of the acm, pp 47-58, april
1991.

patel, ketan, smith, brian c., and rowe, lawrence a.
performance of a software mpeg video decoder 

rowe, lawrence a., patel, ketan, smith, brian c., and liu kim, mpeg
video in software: representation, transmission, and playblack, university
of california, berkeley, ca, february 1994. 

ccir recomendation 601-2



links to relavent topics

 usenet frequently asked questions about mpeg.
mpeg home page.





[ table of contents
| references
| links to other topics
| cs home page
]




&#169; oct, 15 1995  mishaal almashan
cornell university





optimal video transmission
optimal video transmission
optimal video transmission
optimal video transmission
optimal video transmission
optimal video transmission
optimal video transmission
optimal video transmission
optimal video transmission
optimal video transmission