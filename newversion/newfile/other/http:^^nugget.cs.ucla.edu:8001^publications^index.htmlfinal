ucla data mining laboratory publications

 -->





ucla data mining laboratory publications
 -->



-->














 
"mapping a common geoscientific object model to heterogeneous spatial
data repositories",
the 4th acm international workshop on advances in geographic
information systems,
rockville, maryland, nov. 1996.


 
"the design of the falcon framework for application level communication
optimization",
ucla csd technical report #960039, nov. 1996.


 
"mining geophysical data for knowledge",
ieee expert, 11(5):34-44,
oct. 1996.


 
"oasis: an eosdis science computing facility",
international symposium on optical science, engineering, and
instrumentation, conference on earth observing system,
denver, colorado, aug. 1996.


 
"scalable exploratory data mining of distributed geoscientific data",
second international conference on knowledge discovery and data mining,
portland, oregon, aug. 1996.


 
"on heterogeneous distributed geoscientific query processing",
sixth international workshop on research issues in data engineering: 
interoperability of nontraditional database systems,
new orleans, louisiana, feb. 1996.


 
"oasis: an open architecture scientific information system",
sixth international workshop on research issues in data engineering: 
interoperability of nontraditional database systems,
new orleans, louisiana, feb. 1996.




 
"optimization of access to heterogeneous data repositories
in a geoscientific query processing system",
science information systems interoperability conference,
college park, md, nov. 1995.

 
"oasis: an open architecture scientific information system",
science information systems interoperability conference,
college park, md, nov. 1995.

 
"fast spatio-temporal data mining of large geophysical datasets",
the first international conference on knowledge discovery and data
mining,montreal, quebec, canada, aug 1995. 

 
"integrating distributed object management into eos",
geo info systems, 5(5):58-59, may 1995.

 
"exploratory data mining and analysis using conquest",
ieee pacific rim conference on communications, computers, visualization,
and signal processing,
victoria, british columbia, canada, may 1995.




 
"real time data mining, management, and visualization of gcm output",
supercomputing 94 poster,
washington, dc, nov 1994.

 
"the conquest modeling framework for geoscientific data",
ucla csd technical report #940039, oct 1994.

 
"quest: an environment for content-based access to geoscienitfic datasets",
1994 international geoscience and remote sensing symposium,
pasadena, ca, aug. 1994.

 
"quest: content-based access to geophysical databases",
aaai workshop on ai technologies in environmental applications,
seattle, wa, jul-aug 1994.

 
"extracting spatio-temporal patterns from geoscience datasets",
ieee workshop on visualization and machine vision,
seattle, wa, jun 1994.














s. nittel, j. yang, and r.r. muntz,

"mapping a common geoscientific object model to heterogeneous spatial
data repositories",
the 4th acm international workshop on advances in geographic
information systems,
rockville, maryland, nov. 1996.




lately, a need to integrate specialized data management systems
such as geographic information systems (gis), or multimedia
systems has gained importance. a large variety of different
data sets are available in various specialized repositories, and
users would like to access and manipulate these data sets in
a uniform way. additionally, it is desirable to make the
specialized functionality provided by the individual
repositories available to the user application through a
homogeneous interface. at ucla data mining laboratory, we are
developing geopom (geoscientific persistent object manager), a
heterogeneous geoscientific object system which provides a
homogeneous interface to heterogeneous spatial data repositories.
 
geopom provides an object-oriented spatial data model for
the definition of user-defined spatial object types.
internally, geopom maps user-defined spatial object types
to different specialized spatial data repositories, and
employs their storage, search and spatial query capabilities.
in this paper, we focus on the goals, problems and approach
taken in geopom towards defining the spatial functionality
of the heterogeneous geoscientific object system available 
to the user, as well as, the mapping of the spatial object
model to the diverse semantic and functional characteristics
of the heterogeneous spatial data repositories.






e.c. shek, r.r. muntz, and l. fillion,

"the design of the falcon framework for application level communication
optimization",
ucla csd technical report #960039, nov. 1996.



there exist a wide-variety of communication-intensive applications 
which run in networks and platforms of greatly varying characteristics.
this implies the need for application level communication
optimization, which is the optimization of network communication
by exploiting application semantics as well as network and compute
node characteristics.  
in this paper, we propose a flexible object-oriented framework called
falcon for application level communication optimization by allowing
complementary network communication optimization techniques to be
combined in the form of matching stack layers at the endpoints of a
communication channel.   
each stack layer is composed of a pair of matching modules, executed
in the sender and receiver endpoints respectively.
to exploit application knowledge that is only available to one of the
communicating peers, the framework allows an executable stack layer
module to be supplied by either of the communication peers and provides
for safe transport to and execution at the other end of the channel.
automatic rule-based optimization techniques similar to those used 
for extensible database query optimization are developed to 
optimize the communication channel stacks based on the characteristics
of available stack layers, required properties of the channel, and an
application-dependent cost model. 
in addition to providing architectural support for optimizing network
communication, falcon can also be used to introduce support for
new communication and computing paradigms in high-level distributed
computing environments.  for example, while omg's corba distributed
object management architecture adopts remote method invocation as its
primary communication mechanism, data streaming and service migration
can be easily accommodated within the falcon framework. 







e. mesrobian, r.r. muntz, e.c. shek, s. nittel, m. la rouche, 
m. kriguer, c.r. mechoso, j.d. farrara, p. stolorz, and h. nakamura,
"mining geophysical data for knowledge",
ieee expert, 11(5):34-44,
oct. 1996.


exploratory data mining and analysis requires a computing environment
which provides facilities for the user-friendly expression and rapid
execution of "scientific queries". 
oasis exploits emerging distributed object management technologies 
to present a flexible, extensible, and seamless
environment for scientific data analysis,
knowledge discovery, visualization, and collaboration.
in this article we illustrate the use of oasis
for exploratory data analysis and data mining 
of spatio-temporal phenomena from large geophysical datasets.







e. mesrobian, r.r. muntz, e.c. shek, s. nittel, m. kriguer,
and m. larouche,

"oasis: an eosdis science computing facility",
international symposium on optical science, engineering, and
instrumentation, conference on earth observing system,
denver, colorado, aug. 1996.


in the course of global change studies, a scientist would often like
to efficiently store, retrieve, analyze and interpret selected data
sets from a large collection of scientific information scattered
across heterogeneous computational environments, earth observing
system data repositories, and to share the gleaned information with
other scientific communities. to facilitate the above activities, we
have developed oasis, a flexible, extensible, and seamless environment
for scientific data analysis, knowledge discovery, visualization, and
collaboration. 







e.c. shek, r.r. muntz, e. mesrobian, and k. ng,

"scalable exploratory data mining of distributed geoscientific data",

second international conference on knowledge discovery and data mining,
portland, oregon, aug. 1996.



geoscience studies produce data from various observations,
experiments, and simulations at an enormous rate.  
exploratory data mining extracts "content information" from
massive geoscientific datasets to extract knowledge and provide 
a compact summary of the dataset.
in this paper, we discuss how database query processing and
distributed object management techniques can be used to facilitate
geoscientific data mining and analysis.  
some special requirements of large scale geoscientific data mining
that are addressed include geoscientific data modeling, parallel query
processing, and heterogeneous distributed data access. 







e.c. shek, e. mesrobian, and r.r. muntz,

"on heterogeneous distributed geoscientific query processing",

sixth international workshop on research issues in data engineering: 
interoperability of nontraditional database systems,
new orleans, louisiana, feb. 1996.



geoscience studies produce data from various observations,
experiments, and simulations at an enormous rate.  in this paper, we
present an overview of the conquest parallel scientific query
processing system that we are developing at ucla to tackle some of the
scientific data management problems presented by the proliferation of
geographic applications, data formats, and storage systems, as well as
the complexity of data and the computational requirements of
scientific queries.  in particular, our goal is to provide the
necessary combination of expressiveness, ease of use, flexibility, and
efficiency to effectively support the analysis of complex
spatio-temporal geoscientific datasets maintained by heterogeneous
data sources in many different formats.  conquest's data model is rich
yet conceptually simple; it captures some important structural and
semantic properties common to geoscientific data which influence the
choice of query processing strategies, and is flexible enough to serve
as the canonical model for a wide variety of scientific and
non-scientific data.  conquest supports a graphical dataflow
programming environment in which scientists can interactively
manipulate and visualize scientific data.  the extensible parallel
query execution server supports varieties of inter- and intra-operator
parallelism through the use of various support operators.  to provide
a convenient heterogeneous distributed scientific data processing
environment to scientists, the system supports a set of interfaces to
a variety of scientific data sources including several external data
formats and database servers.  we also report some early experiences
with benchmarking the performance of the system.







e. mesrobian, r.r. muntz, e. shek, s. nittel, m. larouche, and m.
krieger,

"oasis: an open architecture scientific information system",

sixth international workshop on research issues in data engineering: 
interoperability of nontraditional database systems,
new orleans, louisiana, feb. 1996.



motivated by the premise that heterogeneity of software applications and
hardware systems is here to stay, we are developing
oasis, a flexible, extensible, and seamless environment for scientific data
analysis, knowledge discovery, visualization, and collaboration. in this
paper we discuss our oasis design goals and present the system architecture
and major components of our prototype environment.







e.c. shek, e. mesrobian, and r.r. muntz,

"optimization of access to heterogeneous data repositories
in a geoscientific query processing system",

science information systems interoperability conference,
college park, md, nov. 1995.








e. mesrobian, r.r. muntz, m. larouche, s. nittel, e. shek, and m.
krieger,
"oasis: an open architecture scientific information system",

science information systems interoperability conference,
college park, md, nov. 1995.








p. stolorz, e. mesrobian, r.r. muntz, e.c. shek, j.r. santos, j. yi, k. ng, 
s.y. chien, h. nakamura, c.r. mechoso, and j.d. farrara,

"fast spatio-temporal data mining of large geophysical datasets",

the first international conference on knowledge discovery and data
mining,
montreal, quebec, canada, aug 1995. 



the important scientific challenge of understanding global climate
change is one that clearly requires the application of knowledge
discovery and data mining techniques on a massive scale.  advances in
parallel supercomputing technology, enabling high-resolution modeling,
as well as in sensor technology, allowing data capture on an
unprecedented scale, conspire to overwhelm present-day analysis
approaches.  we present here early experiences with a prototype
exploratory data analysis environment, conquest, designed to provide
content-based access to such massive scientific datasets.  conquest
(content-based querying in space and time) employs a combination of
workstations and massively parallel processors (mpps) to mine
geophysical datasets possessing a prominent temporal component.  it is
designed to enable complex multi-modal interactive querying and
knowledge discovery, while simultaneously coping with the
extraordinary computational demands posed the scope of the datasets
involved.  after outlining a working prototype, we concentrate here on
the description of several associated feature extraction algorithms
implemented on mpp platforms, together with some typical results.







r.r. muntz, e. mesrobian, c.r. mechoso, d. mccleese, r. haskins,
r. zurek, and t. barnett,
"integrating distributed object management into eos", 
geo info systems, 5(5):58-59, may 1995.








e. mesrobian, r.r. muntz, e.c. shek, j.r. santos, j. yi, k. ng, 
s.y. chien, c.r. mechoso, j.d. farrara, p. stolorz, and h. nakamura,

"exploratory data mining and analysis using conquest",
ieee pacific rim conference on communications, computers, visualization,
and signal processing,
victoria, british columbia, canada, may 1995.



exploratory data mining and analysis requires an extensible environment
which provides facilities for the user-friendly expression and rapid
execution of "scientific queries".  in this paper we present the
conquest environment and illustrate its use for exploratory data analysis
and data mining of spatio-temporal phenomena from geophysical datasets.







e. mesrobian, r.r. muntz, e.c. shek, c.r. mechoso, j.d. farrara, 
j.a. sphar, and p. stolorz,

"real time data mining, management, and visualization of gcm output",
supercomputing 94 poster,
washington, dc, nov 1994.



the output of simulations (e.g., global circulation models)
can run into terabytes.
the computational cost as well as the cost of storing and retrieving
model data can be quite high.  recently there have been some efforts
to develop on-line visualization capabilities that can be used, for
example, to monitor whether the model is behaving properly.
there are however, many other uses for on-line data analysis including
feature extraction, computational steering of the model, and
controlled saving of model output (e.g., more frequent samples of
state information under certain conditions).
each of these applications is a potential client of model output data.
we present a software architecture which stresses modularity and
flexibility and supports a variety of clients.  some preliminary
performance numbers are given from a prototype implementation.







e.c. shek, and r.r. muntz,

"the conquest modeling framework for geoscientific data",
ucla csd technical report #940039, oct 1994.



geoscience studies produce data from various observations,
experiments, and simulations at an enormous rate.  at ucla, we are
developing the conquest parallel scientific query processing system
to effectively support the analysis of complex spatio-temporal 
geoscientific datasets maintained by heterogeneous data sources in 
many different formats.

in this paper, we describe the conquest data modeling framework which
captures some of the important semantics of geoscientific data and 
common processing paradigms.  the central concept behind the
conquest data model is that of the field, which is the association of
geometric cells in a coordinate space with dependent variable values.
cells with different semantics and structures can model a large
variety of traditional and scientific datasets.  the properties of
cells also influence the choice of data storage, indexing, and query
optimization strategies.  in addition to providing a flexible data
model to serve as the canonical model for a wide variety of scientific
and non-scientific data, it is important for a system to
be able to efficiently retrieve and operate on scientific data.
as a result, we define an algebra for the conquest data
model in which queries and operations against scientific data can be
conveniently expressed.  in addition, we present an overview of the
conquest architecture, and some interesting query processing issues 
related to parallelism, extensibility and heterogeneity.







e. mesrobian, e.c. shek, r.r. muntz, and w. cheng,
"quest: an environment for content-based access to geoscienitfic datasets",

1994 international geoscience and remote sensing symposium,
pasadena, ca, aug. 1994.



recent advances in fine and coarse-grained super computers have enable
scientists to create models which, in the past, were computationally
intractable. these advances have also provided scientists with the
opportunity to greatly improve the success of their simulation results
by allowing for finer model resolutions. similarly, advances in sensor technology have led to instrument suites capable of
capturing high spatial resolution, multi-spectral data at very high
rates (e.g., earth observer satellites (eos) are expected to generate
a terabyte of data per day). unfortunately, software environments for
storage, retrieval, analysis, interpretation and visualization of
scientific information have not keep pace with their hardware counterparts. 

we have developed a prototype system called quest to provide
content-based query access to massive datasets. quest employs
workstations as well as teraflop computers to analyze geoscience data
in order to produce spatial-temporal features that are used as
high-level indexes into terabyte datasets. examples are presented of
the use of quest for the content-based access of global circulation
model (gcm) datasets.  







e. mesrobian, r.r. muntz, e.c. shek, c.r. mechoso, j.d. farrara, 
and p. stolorz,

"quest: content-based access to geophysical databases",
aaai workshop on ai technologies in environmental applications,
seattle, wa, jul-aug 1994.



a major challenge facing geophysical science today is the unavailability
of high-level analysis tools with which to study the massive amount of 
data produced by sensors or long simulations of climate models.
as part of a nasa hpcc grand challenge effort [mun92], we have developed
a prototype environment called quest to provide content-based query
access to massive datasets used in geophysical applications.  quest
employs workstations as well as massively parallel processors to produce
spatio-temporal features that are used as high-level indexes into
terabyte datasets.  this paper discusses our continued development of
the quest environment.







e. mesrobian, r.r. muntz, j.r. santos, e.c. shek,
c.r. mechoso, j.d. farrara, and p. stolorz,

"extracting spatio-temporal patterns from geoscience datasets",
ieee workshop on visualization and machine vision,
seattle, wa, jun 1994.



a major challenge facing geophysical science today is the unavailability
of high-level analysis tools with which to study the massive amount of
data produced by sensors or long
simulations of climate models.
we have developed a prototype system called quest to provide content-based
access to massive datasets.  quest employs workstations as well as teraflop
computers to analyze geoscience data to produce spatial-temporal
features that can be used as high-level indexes.
our first application area is global change climate modeling.
in the initial prototype, the first features extracted are cyclones
trajectories from the output of multi-year climate simulations produced
by a general circulation model.
we present an algorithm for cyclone extraction and 
illustrate the use of cyclone indexes to access subsets
of gcm data for further analysis and visualization.






[general]
[projects]
[people]
[publications]
[presentations]
[demos]
[related]




this page copyright &#169 1996; webmaster www@nugget.cs.ucla.edu
 created: 5/12/95; last updated: 11/13/96


 




ucla data mining laboratory publications
ucla data mining laboratory publications
ucla data mining laboratory publications
ucla data mining laboratory publications
ucla data mining laboratory publications
ucla data mining laboratory publications
ucla data mining laboratory publications
ucla data mining laboratory publications
ucla data mining laboratory publications
ucla data mining laboratory publications