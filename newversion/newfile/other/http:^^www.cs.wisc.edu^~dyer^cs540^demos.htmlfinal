interesting ai demos and projects 



 
     interesting ai demos and projects 


  send suggestions for additions to this list to
  dyer@cs.wisc.edu



 agents 
 
   
	interactive video environment  (mit) 
	the interactive video environment (ive) is an experimental
	"testbed" to explore how computer vision and computer agents
	technologies can be used to solve problems of human interface and
	human interaction over networks. the goal of the ive project is to
	develop smart cooperative work/play systems that function
	robustly despite wide variation in network and environmental
	conditions. 

  
   firefly personal music recommendation agent

  
   
	internet softbots  (u. washington) 
	building autonomous agents that interact with
	real-world software environments such as operating systems or databases is a
	pragmatically convenient yet intellectually challenging ai problem. 
	we are utilizing planning and
	machine-learning technology to develop an internet softbot (software robot),
	a customizable and (moderately) intelligent assistant for internet access. the
	softbot accepts goals in a high-level language, generates and executes plans
	to achieve these goals, and learns from its experience. 

  
   letizia: a web browsing agent (mit)
  
   miscellaneous resources on agents
 

 computer vision 
 
  image databases: ibm, virage, kodak, illustra, image info
   telepresence (north carolina, penn, cmu)
   virtualized reality (cmu)
   
	computers watching football (mit)
   
	face recognition (cmu)
   
	image processing with live video sources  (mit)
   
	active vision  (inria, france) (slow link)
   
	basic image processing functions  (visioneering res. lab)
   
	miscellaneous computer vision demos
 

 expert systems 
 
   screening applications for graduate school
 

 game playing 
 
   
	deep blue chess player (ibm)
   
	chinook checkers player (alberta)
   
	diplomacy
 

 machine learning 
 
   
        the ice neural nets hot list has intro material on artificial
        neural networks, as well as some java demonstrations.
   
	alvinn - autonomous vehicle navigation using neural nets (cmu) 
	alvinn uses neural networks to learn visual servoing. it
	watches a person drive for five minutes, and can
	then take over driving. alvinn has been trained to drive on
	dirt paths, single-lane country roads, city streets,
	and multi-lane highways.   click
	 here
	for images of the vehicles and videos of alvinn in action.
   whale identification using a decision tree
 

 natural language processing 
 
   
	chat natural language system  (communications canada) 
	chat (conversational hypertext access technology) is a computer
	program developed by the communications research centre that
	provides easy access to electronic information. chat provides a
	natural-language interface that allows users to ask english
	questions and receive answers.  

  
   
	julia (cmu)

  
   
	netsumm - a text summarizer for web pages (british telecom)

  
   
	start natural language question answering  (mit) 
	ask english questions about
	the m.i.t. artificial intelligence laboratory to a natural language
	system called 
        
	start .  see, for example, snapshots of
	
	asking a question , and
	
	viewing the answer .

 

 robotics 
 
   
	dante ii walking robot (cmu) 
	the cmu field robotics center (frc) developed dante ii, a tethered
	walking robot, which explored the mt. spurr (aleutian range,
	alaska) volcano in july 1994.  the
	use of robotic explorers, such as dante ii, opens a new era in field
	techniques by enabling scientists to remotely conduct research and
	exploration. 

  
   
	mobile robot navigation using stereo vision (jpl) 
	the nasa jsc mobile robot lab recently demonstrated the
	integration of a stereo vision system with a mobile robot for the
	purpose of following people or other robots. 
	during following, the stereo system is constantly feeding updated
	coordinates of the agent being tracked to the mobile robot system.
	the mobile robot takes these coordinates as goal positions and
	attempts to attain the goal position while avoiding obstacles using
	its sonar sensors.  

  
   
	tracking and grasping moving objects (columbia) 
	coordination between an organism's sensing modalities
	and motor control system is a hallmark of intelligent behavior,
	and we are pursuing the goal of
	building an integrated sensing and actuation system that
	can operate in dynamic as opposed to
	static environments. the system we are building is a
	multi-sensor system that integrates work in
	real-time vision, robotic arm control and stable
	grasping of objects. our first attempts at this have
	resulted in a system that can track and stably grasp a
	moving model train in real-time.

  
   
	robot tele-operation (usc) 
	the mercury project allows users to
	tele-operate a robot arm moving over a terrain filled with buried artifacts. a ccd
	camera and pneumatic nozzle mounted on the robot allow users to select
	viewpoints and to direct short bursts of compressed air into the terrain. thus
	users can "excavate" regions within the sand by positioning the arm, delivering a
	burst of air, and viewing the newly cleared region. 

  
   
	miscellaneous robot demos
 

 speech 
 
 decface talking synthetic face (dec)
 laureate text-to-speech synthesis system (british telecom)
 




 interesting ai demos and projects
 interesting ai demos and projects
 interesting ai demos and projects
 interesting ai demos and projects
 interesting ai demos and projects
 interesting ai demos and projects
 interesting ai demos and projects
 interesting ai demos and projects
 interesting ai demos and projects
 interesting ai demos and projects