resource allocation group



	
part of  procsimity  
visualization tool.



resource allocation group
we are the resource allocation group at the 
 university of oregon

department of computer and information science.

keywords: 
parallel and distributed computing, resource management,
allocation, mapping, task assignment, scheduling, distributed
shared memory. 

contents

  research description 
  project archives (technical reports and
	software)
  group members 
  other information resources
 upcoming conferences



research description:

resource management is a key area of research in the drive to
fully realize the performance potential of parallel and distributed
computing systems.  the complexities
involved in managing both hardware and software resources that
number in the hundreds to thousands, under the demands of a diverse
multi-user workload, presents a spectrum of challenging problems
for operating systems designers.  

our research group focuses on the management
of processors and processes in systems
ranging from message-passing multicomputers to loosely-coupled
workstation-based distributed systems.  we have developed
algorithms and software tools for allocation, mapping, placement, scheduling
and migration, with extensions to support fault tolerance,
heterogeneous environments, and real time constraints.
we have also begun to explore issues related to
parallel i/o allocation and scheduling.
our approach involves a blend of theoretical, experimental, and systems
development work. 


processor allocation research: this work involves the design
of processor allocation algorithms
for message-passing machines based on the mesh and k-ary n-cube
network topologies.  processor allocation involves selection of
a subset of processors for assignment to each incoming job request
with the goal of maximizing system throughput.
a simulation and visualization tool called 
 procsimity
has been developed to support experimentation and performance analysis
with a wide range of allocation algorithms on a spectrum of machine
architectures.  this work also involves empirical experimentation
with state of the art machines through collaboration with bill nitzberg at
 nasa ames nas. 

the 
oregami
 project: involves the development of algorithms and abstractions
for the mapping of parallel algorithms to message-passing machines
when both the computation and the interconnection network are regular
in structure.  in collaboration with sanjay rajopadhye of 
 irisa , 
france, we have developed a formalism for describing both the computation
and the target architecture which aids in the development of efficient
and effective mapping functions.  this approach exploits regularity
in both the spatial and temporal communication patterns exhibited
by many parallel applications.  


current group members

  virginia m. lo 
	 lo@cs.uoregon.edu
 bella bose
	 bose@cs.orst.edu
 sanjay rajopadhye
	 sanjay@chert.cs.orst.edu
 joshua dyer
	 jdyer@cs.uoregon.edu
  wanqian liu 
	 wliu@cs.uoregon.edu
  jens mache
	 jens@cs.uoregon.edu
 jayne valenti miller
	 jayne@cs.uoregon.edu
 bill nitzberg
	 nitzberg@nas.nasa.gov
 junying wang
	 jwang@cs.uoregon.edu
 douglas e westervelt
	 dwesterv@cs.uoregon.edu
  kurt windisch
	 kurtw@cs.uoregon.edu



other information resources:

our metacomputing notes and links.

ohter resources:

 other supercomputing, parallel computing, and high-performance computer 
	architecture 
	 research groups
 
	parallel i/o archive 
 
	collected cs bibliographies and a search mechanism, 
	glimpse.
 
	unified cs tech report index - searchable index of computer science
	technical report abstracts
 list of computer science 
	
	technical report archive sites.
 high performance computing 
	 home page from planet earth home page.





kurtw@cs.uoregon.edu