theory refinement

theory refinement

to view a paper, click on the open book image.  









combining symbolic and connectionist learning methods to refine
certainty-factor rule-bases
j. jeffrey mahoney

ph.d. thesis, department of computer sciences, university of texas at austin, may, 1996.


this research describes the system rapture, which is designed to
revise rule bases expressed in certainty-factor format.  recent
studies have shown that learning is facilitated when biased with
domain-specific expertise, and have also shown that many real-world
domains require some form of probabilistic or uncertain reasoning in
order to successfully represent target concepts. rapture was designed
to take advantage of both of these results. 

beginning with a set of certainty-factor rules, along with
accurately-labelled training examples, rapture makes use of both
symbolic and connectionist learning techniques for revising the rules,
in order that they correctly classify all of the training examples. a
modified version of backpropagation is used to adjust the certainty
factors of the rules, id3's information-gain heuristic is used to add
new rules, and the upstart algorithm is used to create new hidden
terms in the rule base. 

results on refining four real-world rule bases are presented that
demonstrate the effectiveness of this combined approach.  two of these
rule bases were designed to identify particular areas in strands of
dna, one is for identifying infectious diseases, and the fourth
attempts to diagnose soybean diseases.  the results of rapture are
compared with those of backpropagation, c4.5, kbann, and other
learning systems.  rapture generally produces sets of rules that are
more accurate that these other systems, often creating smaller sets of
rules and using less training time. 










 refinement of bayesian networks by combining connectionist and
symbolic techniques 
sowmya ramanchandran

ph.d. proposal, department of computer sciences, university of texas
at austin, 1995. 


bayesian networks provide a mathematically sound formalism for
representing and reasoning with uncertain knowledge and are as such
widely used. however, acquiring and capturing knowledge in this
framework is difficult. there is a growing interest in formulating
techniques for learning bayesian networks inductively. while the
problem of learning a bayesian network, given complete data, has been
explored in some depth, the problem of learning networks with
unobserved causes is still open. in this proposal, we view this
problem from the perspective of theory revision and present a novel
approach which adapts techniques developed for revising theories in
symbolic and connectionist representations.  thus, we assume that the
learner is given an initial approximate network (usually obtained from
a expert). our technique inductively revises the network to fit the
data better.  our proposed system has two components: one component
revises the parameters of a bayesian network of known structure, and
the other component revises the structure of the network. the
component for parameter revision maps the given bayesian network into
a multi-layer feedforward neural network, with the parameters mapped
to weights in the neural network, and uses standard backpropagation
techniques to learn the weights. the structure revision component uses
qualitative analysis to suggest revisions to the network when it fails
to predict the data accurately. the first component has been
implemented and we will present results from experiments on real world
classification problems which show our technique to be effective.  we
will also discuss our proposed structure revision algorithm, our plans
for experiments to evaluate the system, as well as some extensions to
the system.









a novel application of theory refinement to student modeling
paul baffes and raymond j. mooney

proceedings of the thirteenth national conference on aritificial intelligence,
pp. 403-408, portland, or, august, 1996. (aaai-96)


theory refinement systems developed in machine learning automatically
modify a knowledge base to render it consistent with a set of
classified training examples. we illustrate a novel application of
these techniques to the problem of constructing a student model for an
intelligent tutoring system (its). our approach is implemented in an
its authoring system called assert which uses theory refinement to
introduce errors into an initially correct knowledge base so that it
models incorrect student behavior. the efficacy of the approach has
been demonstrated by evaluating a tutor developed with assert with 75
students tested on a classification task covering concepts from an
introductory course on the c++ programming language. the system
produced reasonably accurate models and students who received feedback
based on these models performed significantly better on a post test
than students who received simple reteaching.









 refinement-based student modeling and automated bug library 
construction
paul baffes and raymond mooney

journal of artificial intelligence in education, 7, 1
(1996), pp. 75-116.



a critical component of model-based intelligent tutoring sytems is a
mechanism for capturing the conceptual state of the student, which
enables the system to tailor its feedback to suit individual strengths
and weaknesses.  to be useful such a modeling technique must be
practical, in the sense that models are easy to construct, and
effective, in the sense that using the model actually impacts student
learning.  this research presents a new student modeling technique
which can automatically capture novel student errors using only
correct domain knowledge, and can automatically compile trends across
multiple student models.  this approach has been implemented as a
computer program, assert, using a machine learning technique called
theory refinement, which is a method for automatically revising a
knowledge base to be consistent with a set of examples.  using a
knowledge base that correctly defines a domain and examples of a
student's behavior in that domain, assert models student errors by
collecting any refinements to the correct knowledege base which are
necessary to account for the student's behavior.  the efficacy of the
approach has been demonstrated by evaluating assert using 100 students
tested on a classification task covering concepts from an introductory
course on the c++ programming language.  students who received
feedback based on the models automatically generated by assert
performed significantly better on a post test than students who
received simple teaching.










revising bayesian network parameters using backpropagation
sowmya ramachandran and raymond j. mooney

proceedings of the international conference on neural
networks (icnn-96), special session on knowledge-based artificial
neural networks, washington dc, june 1996. 


the problem of learning bayesian networks with hidden variables is known to
be a hard problem. even the simpler task of learning just the conditional
probabilities on a bayesian network with hidden variables is hard. in this
paper, we present an approach that learns the conditional probabilities on
a bayesian network with hidden variables by transforming it into a
multi-layer feedforward neural network (ann). the conditional probabilities
are mapped onto weights in the ann, which are then learned using standard
backpropagation techniques. to avoid the problem of exponentially large
anns, we focus on bayesian networks with noisy-or and noisy-and
nodes. experiments on real world classification problems demonstrate the
effectiveness of our technique.











  automatic student modeling and bug library construction using theory 
refinement    

paul t. baffes 

ph.d. thesis, department of computer sciences, university of texas at
austin, december, 1994.


the history of computers in education can be characterized by a
continuing effort to construct intelligent tutorial programs
which can adapt to the individual needs of a student in a
one-on-one setting. a critical component of these intelligent
tutorials is a mechanism for modeling the conceptual state of the
student so that the system is able to tailor its feedback to suit
individual strengths and weaknesses. the primary contribution of
this research is a new student modeling technique which can
automatically capture novel student errors using only correct
domain knowledge, and can automatically compile trends across
multiple student models into bug libraries. this approach has
been implemented as a computer program, assert, using a machine
learning technique called theory refinement which is a method for
automatically revising a knowledge base to be consistent with a
set of examples. using a knowledge base that correctly defines a
domain and examples of a student's behavior in that domain,
assert models student errors by collecting any refinements to the
correct knowledge base which are necessary to account for the
student's behavior. the efficacy of the approach has been
demonstrated by evaluating assert using 100 students tested on a
classification task using concepts from an introductory course on
the c++ programming language. students who received feedback
based on the models automatically generated by assert performed
significantly better on a post test than students who received
simple reteaching.










  comparing methods for refining certainty factor rule-bases   

j. jeffrey mahoney and raymond j. mooney  

 proceedings of the eleventh international workshop on machine
learning, pp. 173-180, rutgers, nj, july 1994. (ml-94) 


this paper compares two methods for refining uncertain knowledge bases using
propositional certainty-factor rules.  the first method, implemented in the
rapture system, employs neural-network training to refine the certainties
of existing rules but uses a symbolic technique to add new rules.  the second
method, based on the one used in the kbann system, initially adds a
complete set of potential new rules with very low certainty and allows
neural-network training to filter and adjust these rules.  experimental results
indicate that the former method results in significantly faster training and
produces much simpler refined rule bases with slightly greater accuracy.









  modifying network architectures for certainty-factor rule-base revision
   
j. jeffrey mahoney and raymond j. mooney  

 proceedings of the international symposium on integrating
knowledge and neural heuristics 1994, pp. 75-85, pensacola, fl,
may 1994. (isiknh-94) 

 
this paper describes rapture --- a system for revising
probabilistic rule bases that converts symbolic rules into a
connectionist network, which is then trained via connectionist
techniques.  it uses a modified version of backpropagation to refine
the certainty factors of the rule base, and uses id3's
information-gain heuristic (quinlan) to add new rules.  work is
currently under way for finding improved techniques for modifying
network architectures that include adding hidden units using the
upstart algorithm (frean).  a case is made via comparison with fully
connected connectionist techniques for keeping the rule base as close
to the original as possible, adding new input units only as needed.









  extending theory refinement to m-of-n rules   

paul t. baffes and raymond j. mooney  

 informatica, 17 (1993), pp. 387-397. 


in recent years, machine learning research has started addressing a problem
known as  theory refinement. the goal of a theory refinement learner is
to modify an incomplete or incorrect rule base, representing a domain theory,
to make it consistent with a set of input training examples. this paper
presents a major revision of the either propositional theory refinement
system. two issues are discussed. first, we show how run time efficiency can
be greatly improved by changing from a exhaustive scheme for computing
repairs to an iterative greedy method. second, we show how to extend
either to refine mofn rules. the resulting algorithm, neither (new 
either), is more than an order of magnitude faster and produces
significantly more accurate results with theories that fit the mofn
format. to demonstrate the advantages of neither, we present experimental
results from two real-world domains.









  learning to model students: using theory refinement to detect
misconceptions  

paul t. baffes  

ph.d. proposal, department of computer sciences, university of texas
at austin, 1993. 



a new student modeling system called assert is described which uses domain
independent learning algorithms to model unique student errors and to
automatically construct bug libraries. assert consists of two learning phases.
the first is an application of theory refinement techniques for constructing
student models from a correct theory of the domain being tutored. the second
learning cycle automatically constructs the bug library by extracting common
refinements from multiple student models which are then used to bias future
modeling efforts. initial experimental data will be presented which suggests
that assert is a more effective modeling system than other induction techniques
previously explored for student modeling, and that the automatic bug library
construction significantly enhances subsequent modeling efforts.









  symbolic revision of theories with m-of-n rules   

paul t. baffes and raymond j. mooney  

 proceedings of the thirteenth international joint conference on artificial
intelligence, pp. 1135-1140, chambery, france, 1993. (ijcai-93) 


this paper presents a major revision of the either propositional theory
refinement system. two issues are discussed. first, we show how run time
efficiency can be greatly improved by changing from a exhaustive scheme for
computing repairs to an iterative greedy method. second, we show how to extend
either to refine m-of-n rules. the resulting algorithm, neither (new either),
is more than an order of magnitude faster and produces significantly more
accurate results with theories that fit the m-of-n format. to demonstrate the
advantages of neither, we present preliminary experimental results comparing it
to either and various other systems on refining the dna promoter domain theory.









  combining connectionist and symbolic learning to refine certainty-factor 
rule-bases   

j. jeffrey mahoney and raymond j. mooney  

 connection science, 5 (1993), pp. 339-364. (special issue on
architectures for integrating neural and symbolic processing) 


this paper describes rapture --- a system for revising probabilistic knowledge
bases that combines connectionist and symbolic learning methods. rapture uses
a modified version of backpropagation to refine the certainty factors of a
mycin-style rule base and it uses id3's information gain heuristic to add
new rules.  results on refining three actual expert knowledge bases demonstrate
that this combined approach generally performs better than previous methods.










  refinement of first-order horn-clause domain theories  

bradley l. richards and raymond j. mooney 

 machine learning 19,2 (1995), pp. 95-131. 

 knowledge acquisition is a difficult and time-consuming
task, and as error-prone as any human activity.  the task of
automatically improving an existing knowledge base using learning
methods is addressed by a new class of systems performing  theory
refinement.  until recently, such systems were limited to
propositional theories.  this paper presents a system, forte
(first-order revision of theories from examples), for refining
first-order horn-clause theories.  moving to a first-order
representation opens many new problem areas, such as logic program
debugging and qualitative modelling, that are beyond the reach of
propositional systems.  forte uses a hill-climbing approach to revise
theories.  it identifies possible errors in the theory and calls on a
library of operators to develop possible revisions.  the best revision
is implemented, and the process repeats until no further revisions are
possible.  operators are drawn from a variety of sources, including
propositional theory refinement, first-order induction, and inverse
resolution.  forte has been tested in several domains including
logic programming and qualitative modelling.  








  combining symbolic and neural learning to revise probabilistic theories   

j. jeffrey mahoney & raymond j. mooney  

 proceedings of the 1992 machine learning workshop on integrated
learning in real domains, aberdeen scotland, july 1992. 


this paper describes rapture --- a system for revising probabilistic
theories that combines symbolic and neural-network learning methods. 
rapture uses a modified version of backpropagation to refine the certainty
factors of a mycin-style rule-base and it uses id3's information gain heuristic
to add new rules.  results on two real-world domains demonstrate that this
combined approach performs as well or better than previous methods.









  using theory revision to model students and acquire stereotypical errors   

paul t. baffes and raymond j. mooney  

 proceedings of the fourteenth annual conference of the cognitive
science society, pp. 617-622, bloomington, in, july 1992. 


student modeling has been identified as an important component to the long
term development of intelligent computer-aided instruction (icai) systems. two
basic approaches have evolved to model student misconceptions. one uses a
static, predefined library of user bugs which contains the misconceptions
modeled by the system. the other uses induction to learn student
misconceptions from scratch. here, we present a third approach that uses a
machine learning technique called theory revision. using theory revision
allows the system to automatically construct a bug library for use in modeling
while retaining the flexibility to address novel errors.









  a preliminary pac analysis of theory revision   

raymond j. mooney  
march 1992 

 computational learning theory and natural learning systems, 
vol.  3, t. petsche, s. judd, and s. hanson, eds., mit press, 1995, pp. 43-53. 



this paper presents a preliminary analysis of the sample complexity of theory
revision within the framework of pac (probably approximately correct)
learnability theory.  by formalizing the notion that the initial theory is
``close'' to the correct theory we show that the sample complexity of an
optimal propositional horn-clause theory revision algorithm is $o( ( \ln 1 /
\delta + d \ln (s_0 + d + n) ) / \epsilon)$, where $d$ is the {\em syntactic
distance} between the initial and correct theories, $s_0$ is the size of
initial theory, $n$ is the number of observable features, and $\epsilon$ and
$\delta$ are the standard pac error and probability bounds. the paper also
discusses the problems raised by the computational complexity of theory
revision.









  automated debugging of logic programs via theory revision   

raymond j. mooney & bradley l. richards  

 proceedings of the second international workshop on inductive
logic programming, tokyo, japan, june 1992. 


this paper presents results on using a theory revision system to automatically
debug logic programs. forte is a recently developed system for revising
function-free horn-clause theories.  given a theory and a set of training
examples, it performs a hill-climbing search in an attempt to minimally modify
the theory to correctly classify all of the examples.  forte makes use of
methods from propositional theory revision, horn-clause induction (foil),
and inverse resolution.  the system has has been successfully used to debug
logic programs written by undergraduate students for a programming languages
course.









  batch versus incremental theory refinement   

raymond j. mooney  

 proceedings of aaai spring symposium on knowledge
assimilation, standford, ca, march, 1992. 


most existing theory refinement systems are not incremental. however, any
theory refinement system whose input and output theories are compatible can be
used to incrementally assimilate data into an evolving theory.  this is done by
continually feeding its revised theory back in as its input theory.  an
incremental batch approach, in which the system assimilates a batch of examples
at each step, seems most appropriate for existing theory revision systems.
experimental results with the either theory refinement system demonstrate
that this approach frequently increases efficiency without significantly
decreasing the accuracy or the simplicity of the resulting theory.  however, if
the system produces bad initial changes to the theory based on only small
amount of data, these bad revisions can ``snowball'' and result in an overall
decrease in performance.










  a multistrategy approach to theory refinement   

raymond j. mooney & dirk ourston  

 machine learning: a multistrategy approach, vol. iv, r.s. michalski
& g. teccuci (eds.), pp.141-164, morgan kaufman, san mateo, ca, 1994. 


this chapter describes a multistrategy system that employs independent modules
for deductive, abductive, and inductive reasoning to revise an arbitrarily
incorrect propositional horn-clause domain theory to fit a set of preclassified
training instances.  by combining such diverse methods, either is able
to handle a wider range of imperfect theories than other theory revision
systems while guaranteeing that the revised theory will be consistent with the
training data.  either has successfully revised two actual expert
theories, one in molecular biology and one in plant pathology. the results
confirm the hypothesis that using a multistrategy system to learn from both
theory and data gives better results than using either theory or data alone.









  theory refinement combining analytical and empirical methods  

dirk ourston and raymond j. mooney  

 artificial intelligence, 66 (1994), pp. 311--344. 


this article describes a comprehensive approach to automatic theory revision.
given an imperfect theory, the approach combines explanation attempts for
incorrectly classified examples in order to identify the failing portions of
the theory. for each theory fault, correlated subsets of the examples are used
to inductively generate a correction. because the corrections are 
focused, they tend to preserve the structure of the original theory.  because
the system starts with an approximate domain theory, in general fewer training
examples are required to attain a given level of performance (classification
accuracy) compared to a purely empirical system. the approach applies to
classification systems employing a propositional horn-clause theory. the system
has been tested in a variety of application domains, and results are presented
for problems in the domains of molecular biology and plant disease diagnosis.









  improving shared rules in multiple category domain theories   

dirk ourston and raymond j. mooney  

 proceedings of the eighth international machine learning
workshop, pp. 534-538, evanston, il, june 1991. 


this paper presents an approach to improving the classification performance of
a multiple category theory by correcting intermediate rules which are shared
among the categories.  using this technique, the performance of a theory in one
category can be improved through training in an entirely different category.
examples of the technique are presented and experimental results are given.










  constructive induction in theory refinement   

raymond j. mooney and dirk ourston  

 proceedings of the eighth international machine learning
workshop, pp. 178-182, evanston, il. june 1991. 


this paper presents constructive induction techniques recently added to the
either theory refinement system.  these additions allow either to handle
arbitrary gaps at the ``top,'' ``middle,'' and/or ``bottom'' of an incomplete
domain theory.   intermediate concept utilization employs existing rules
in the theory to derive higher-level features for use in induction.  
intermediate concept creation employs inverse resolution to introduce new
intermediate concepts in order to fill gaps in a theory that span multiple
levels.  these revisions allow either to make use of imperfect domain theories
in the ways typical of previous work in both constructive induction and theory
refinement.  as a result, either is able to handle a wider range of theory
imperfections than does any other existing theory refinement system.









  theory refinement with noisy data   

raymond j. mooney and dirk ourston  

technical report ai 91-153, artificial intelligence lab, university of
texas at austin, march 1991. 


this paper presents a method for revising an approximate domain theory based on
noisy data. the basic idea is to avoid making changes to the theory that
account for only a small amount of data. this method is implemented in the
either propositional horn-clause theory revision system.  the paper
presents empirical results on artificially corrupted data to show that this
method successfully prevents over-fitting.  in other words, when the data is
noisy, performance on novel test data is considerably better than revising the
theory to completely fit the data. when the data is not noisy, noise processing
causes no significant degradation in performance.  finally, noise processing
increases efficiency and decreases the complexity of the resulting theory.








estlin@cs.utexas.edu